{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNogJ64SLD3rXCHlCA+1U1b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38539aa7e99740fe9644a03fc4064f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d841cad1aa247beb66c4c5a30424683",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42b070f8a4584137873d45988792c391",
              "IPY_MODEL_7575ca3ca6c14490942b9afaecd7c96a"
            ]
          }
        },
        "3d841cad1aa247beb66c4c5a30424683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42b070f8a4584137873d45988792c391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c09f1fc31ae04f8d8fe7e95a8c926658",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6b3edcda3d741d796305e2457852088"
          }
        },
        "7575ca3ca6c14490942b9afaecd7c96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8804d894dc2d4880a78b607d1cb8412d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 119MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7f8b65391db4d05bf03e05ce06e0986"
          }
        },
        "c09f1fc31ae04f8d8fe7e95a8c926658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6b3edcda3d741d796305e2457852088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8804d894dc2d4880a78b607d1cb8412d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7f8b65391db4d05bf03e05ce06e0986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qwaszx-2015/Test_PO/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MglWzjNbkMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d24528d-b332-4556-fb0c-da5194a0d562"
      },
      "source": [
        "!pip install google-api-python-client\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from collections import *\n",
        "import cv2\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import random\n",
        "import albumentations as A"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (1.12.8)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.30.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (0.0.4)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.26.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (4.2.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (56.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client) (0.2.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (20.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (3.12.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2018.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.16.0->google-api-python-client) (0.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT194bo_b5wk"
      },
      "source": [
        "# задание 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGkw71yvcJ1e"
      },
      "source": [
        "def download_data(file_id, file_name):\n",
        "  import io\n",
        "  from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "  request = drive_service.files().get_media(fileId=file_id)\n",
        "  downloaded = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(downloaded, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "    \n",
        "  downloaded.seek(0)\n",
        "  with open(file_name, \"wb\") as f:\n",
        "    f.write(downloaded.read())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn8bCYDaS2Rd",
        "outputId": "399aa5a2-6979-4e1f-a577-bf36a9810590"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "file_id = '1LLuypl_OCOsV78SxTIV41LvVfTByIkjQ'\n",
        "file_name = 'task1.zip'\n",
        "\n",
        "download_data(file_id, file_name)\n",
        "\n",
        "!unzip task1.zip"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  task1.zip\n",
            "replace task1/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/10.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/13.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/17.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/20.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/23.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/27.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/3.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/30.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/33.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/37.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/40.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task1/7.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLiUm3XGTiOr"
      },
      "source": [
        "Архив скачен и распаковн. Переведем изображение в градации серого, затем обрежем по заданным границам, чтобы посчитать среднюю яркость определенного участка изображения, чтобы посчитать среднюю яркость определенного участка изображения. Потом узнаем параметры вырезанного участка. В функции вернем среднее арифметическое."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIsjG9rMUFJb"
      },
      "source": [
        "def average_brightness(img, left_bound, right_bound, bottom_bound, top_bound):\n",
        "  if right_bound < left_bound or top_bound < bottom_bound:\n",
        "    raise Exception('Wrong bounds!')\n",
        "  gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  cropped_gray_image = gray_image[bottom_bound:top_bound, left_bound:right_bound]\n",
        "  h, w = cropped_gray_image.shape\n",
        "  denominator = h * w\n",
        "  nominator = 0\n",
        "  for i in range(h):\n",
        "    for k in range(w):\n",
        "      nominator += cropped_gray_image[i, k]\n",
        "  return nominator / denominator\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RF-STBcUkvf",
        "outputId": "b31de061-ca97-4d9a-e7ea-c299017c2ae7"
      },
      "source": [
        "left_bound = 80\n",
        "right_bound = 110\n",
        "bottom_bound = 1010\n",
        "top_bound = 1030\n",
        "data_dir = 'task1/'\n",
        "ev = []\n",
        "avg_brightness = []\n",
        "for filename in os.listdir(data_dir):\n",
        "  cur_ev = int(filename[0: -len('.jpg')]) - 20\n",
        "  print(f'process {cur_ev}')\n",
        "  ev.append(cur_ev)\n",
        "  image = cv2.imread(data_dir + filename)\n",
        "  avg_brightness.append(average_brightness(image, left_bound, right_bound, bottom_bound, top_bound))\n",
        "\n",
        "[ev, avg_brightness]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "process 10\n",
            "process 13\n",
            "process -17\n",
            "process -13\n",
            "process -3\n",
            "process -7\n",
            "process -20\n",
            "process -10\n",
            "process 7\n",
            "process 17\n",
            "process 3\n",
            "process 20\n",
            "process 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 13, -17, -13, -3, -7, -20, -10, 7, 17, 3, 20, 0],\n",
              " [190.03833333333333,\n",
              "  172.47333333333333,\n",
              "  129.46166666666667,\n",
              "  112.59666666666666,\n",
              "  151.04166666666666,\n",
              "  150.97,\n",
              "  62.29666666666667,\n",
              "  170.08,\n",
              "  187.76833333333335,\n",
              "  195.23166666666665,\n",
              "  167.17333333333335,\n",
              "  211.15666666666667,\n",
              "  150.48833333333334]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-38h-okRWMFW",
        "outputId": "3accbf61-36ad-403a-d66a-17c4b49e88c4"
      },
      "source": [
        "plt.scatter(ev, avg_brightness)\n",
        "plt.xlabel('Изображения')\n",
        "plt.ylabel('Средняя яркость')\n",
        "plt.grid()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "D1TLe2zrWMY_",
        "outputId": "c1a6b439-5b8a-411b-96b3-0f36d4c6337c"
      },
      "source": [
        "plt.scatter(ev, np.log10(avg_brightness))\n",
        "plt.xlabel('Изображения')\n",
        "plt.ylabel('Средняя яркость log 10')\n",
        "plt.grid()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN_5i-W2eO42"
      },
      "source": [
        "# задание 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3DNsvvKeWys"
      },
      "source": [
        "В методе change_saturation передаем название файла с изображением и коэффициент умножения. Изображение считывается в формате BGR в режиме 1, при котором считывается только цвет без данных о прозрачности. Потом изображение конвертируется из BGR в LAB и делится на 3 канала l, a и b. Каналы a и b домножаются на коэффициент. Однако если коэффициент будет слишком большим, то значение канала будет показывать некорректный цвет, например, розовый станет зеленым. Поэтому в цикле каждому пикселю выставляем минимум из максимально допустимого значения канала и (текущее значение * коэффициент).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtpA6x3-f9cv"
      },
      "source": [
        "def change_saturation(imagename, ratio=1.2):\n",
        "  bgr_image = cv2.imread(imagename, 1)\n",
        "  lab_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2LAB)\n",
        "  l = np.array(lab_image[:, :, 0], np.float32)\n",
        "  a = np.array(lab_image[:, :, 1], np.float32)\n",
        "  b = np.array(lab_image[:, :, 2], np.float32)\n",
        "  h, w = a.shape\n",
        "  for i in range(h):\n",
        "    for k in range(w):\n",
        "      a[i, k] = min(255, a[i, k] * ratio)\n",
        "  h, w = b.shape\n",
        "  for i in range(h):\n",
        "    for k in range(w):\n",
        "      b[i, k] = min(255, b[i, k] * ratio)\n",
        "  res = cv2.merge([l, a, b])\n",
        "  res = cv2.cvtColor(res.astype('uint8'), cv2.COLOR_LAB2BGR)\n",
        "  cv2.imwrite('change_saturation_' + str(ratio) + '_' + imagename, res)\n",
        "  print('метод change saturation успешно отработал')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoN6SKnbgGDV"
      },
      "source": [
        "В цветовом пространстве Lab значение светлоты отделено от значения хроматической составляющей цвета (тон, насыщенность). Светлота задана координатой L (изменяется от 0 до 100, то есть от самого темного до самого светлого), хроматическая составляющая — двумя декартовыми координатами a и b. Первая обозначает положение цвета в диапазоне от зеленого до пурпурного, вторая — от синего до желтого."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTf-fFOSg6hw"
      },
      "source": [
        "def change_brightness(image_name, delta=50):\n",
        "  image = cv2.imread(image_name, 1)\n",
        "  lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "  l = np.array(lab_image[:, :, 0], np.float32)\n",
        "  h, w = l.shape\n",
        "  for i in range(h):\n",
        "    for k in range(w):\n",
        "      # Если выйдем за границы 255, в некоторых местах \n",
        "      # вместо белого получим черные пятна\n",
        "      l[i, k] = min(255, l[i, k] + delta)\n",
        "  a = np.array(lab_image[:, :, 1], np.float32)\n",
        "  b = np.array(lab_image[:, :, 2], np.float32)\n",
        "  res = cv2.merge([l, a, b])\n",
        "  res = cv2.cvtColor(res.astype('uint8'), cv2.COLOR_LAB2BGR)\n",
        "  cv2.imwrite('change_brightness_' + str(delta) + '_' + image_name, res)\n",
        "  print('метод change brightness успешно отработал')\n",
        "  "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYDPck-2iuzy"
      },
      "source": [
        "В метод change_brightness также как и в предыдущий передается название изображения и и дельта, на которую изменится показатель светлоты. Изображение считывается в формате BGR в режиме 1, при котором считывается только цвет без данных о прозрачности. Потом изображение конвертируется из BGR в LAB и делится на 3 канала l, a и b. В цикле к каждому пикселю канала l прибавляется дельта. Однако так мы можем вылететь за границы допустимой светлоты и вместо белого получить черные провалы. Поэтому пикселю присвается минимум из (текущее значение + дельта) и максимально допустимого значения светлоты. Потом массивы каналов сливаются в \"единое\" изображение и конвертируются обратно в BGR.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmwVKSjbixSr",
        "outputId": "9eff068d-a952-4f44-dfa8-59d008897cbb"
      },
      "source": [
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "file_id_for_saturation = '1cTJ7qZ9f9TB-5nG02l9myiubJko3ftmf'\n",
        "file_name_for_saturation = 'ph1.jpg'\n",
        "\n",
        "file_id_for_brightness = '1UeCxAyl9sWRZc-fU0WMoCPIaW4cDIXUH'\n",
        "file_name_for_brightness = 'ph2.jpg'\n",
        "\n",
        "download_data(file_id_for_saturation, file_name_for_saturation)\n",
        "download_data(file_id_for_brightness, file_name_for_brightness)\n",
        "\n",
        "\n",
        "\n",
        "change_saturation('ph1.jpg', 1.3)\n",
        "change_brightness('ph2.jpg', 80)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "метод change saturation успешно отработал\n",
            "метод change brightness успешно отработал\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWDppidlp70R"
      },
      "source": [
        "# задание 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP-57VWvqF_x"
      },
      "source": [
        "Список заданий для выполнения над изображением:\n",
        "\n",
        "Выравнивание гистограммы;\n",
        "Локальное выравнивание гистограммы;\n",
        "Гауссовское размытие;\n",
        "Фильтры Собеля и Лапласа;\n",
        "Блендинг через альфа канал.\n",
        "В архиве task3 хранятся мои изображения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4951IfhLH5co"
      },
      "source": [
        "1. Выравнивание гистограммы. Чтобы не потерять цвет, переводим изображение из BGR в YUV, применяем equalizeHist к третьему каналу и конвертируем изображение обратно в BGR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjx5ZzZqHOP"
      },
      "source": [
        "def place_to_root(path):\n",
        "  return os.path.basename(path) #функция вспомогательная, для хранения даннных в корневой папке\n",
        "\n",
        "def equalizeHistFunction(image_name):\n",
        "  image = cv2.imread(image_name)\n",
        "  image_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
        "  image_yuv[:,:,0] = cv2.equalizeHist(image_yuv[:, :, 0])\n",
        "  res = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2BGR)\n",
        "  cv2.imwrite('equalizeHistFunction ' + image_name, res)\n",
        "\n",
        "equalizeHistFunction(place_to_root('content/ph1.jpg'))\n",
        "equalizeHistFunction(place_to_root('content/ph2.jpg'))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-iTZbvbOamb"
      },
      "source": [
        "2. Локальное выравнивание гистограммы. CLAHE (Contrast Limited Adaptive Histogram Equalization) делит изображение на небольшие части и выравнивает гистограммы отдельно на каждом участке, что позволяет добиться более ровного изображения, без пересветов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esBI0OztOdyP"
      },
      "source": [
        "def claheFunction(image_name, tile_size=(8, 8)):\n",
        "  image = cv2.imread(image_name)\n",
        "  image_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=tile_size)\n",
        "  image_yuv[:, :, 0] = clahe.apply(image_yuv[:, :, 0])\n",
        "  res = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2BGR)\n",
        "  cv2.imwrite('claheFunction' + str(tile_size[0]) + '_' + str(tile_size[1]) + '_' + image_name, res)\n",
        "\n",
        "claheFunction(place_to_root('content/ph1.jpg'))\n",
        "claheFunction(place_to_root('content/ph2.jpg'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4VI4HItPfXV"
      },
      "source": [
        "3. Гаусовское размытие. Указываем ширину и высоту ядра Гауссианы, числа должны быть позитивными и нечетными."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWPGwiBnPgwK"
      },
      "source": [
        "def gaussianFuncBlur(image_name, kernel_size=21):\n",
        "    image = cv2.imread(image_name)\n",
        "    res = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigmaX=0)\n",
        "    cv2.imwrite('gaussianFuncBlur' + str(kernel_size) + '_' + image_name, res)\n",
        "\n",
        "gaussianFuncBlur(place_to_root('content/ph1.jpg'))\n",
        "gaussianFuncBlur(place_to_root('content/ph2.jpg'))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Pvxy0LRsTb"
      },
      "source": [
        "4. Фильтр Собеля и Лапласа. Для фильтра Собеля возьмем способ поиска производной по х."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_USE7A_jUcn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSv6MScWRttu"
      },
      "source": [
        "def sobel_x(image_name):\n",
        "  image = cv2.imread(image_name, 0)\n",
        "  res = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
        "  cv2.imwrite('sobel_x_' + image_name, res)\n",
        "\n",
        "\n",
        "def sobel_y(image_name):\n",
        "  image = cv2.imread(image_name, 0)\n",
        "  res = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
        "  cv2.imwrite('sobel_y_' + image_name, res)\n",
        "\n",
        "\n",
        "def laplas(image_name):\n",
        "  image = cv2.imread(image_name, 0)\n",
        "  res = cv2.Laplacian(image, cv2.CV_64F)\n",
        "  cv2.imwrite('laplas_' + image_name, res)\n",
        "    \n",
        "\n",
        "laplas(place_to_root('content/ph1.jpg'))\n",
        "laplas(place_to_root('content/ph2.jpg'))\n",
        "sobel_x(place_to_root('content/ph1.jpg'))\n",
        "sobel_x(place_to_root('content/ph2.jpg'))\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C62fIZ1BSm5I"
      },
      "source": [
        "5. Блендинг через альфа канал."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUL8F4K_SpR-"
      },
      "source": [
        "def alpha_blending(foreground_image_name, background_image_name, alpha_mask_image_name):\n",
        "  foreground = cv2.imread(foreground_image_name)\n",
        "  background = cv2.imread(background_image_name)\n",
        "  alpha = cv2.imread(alpha_mask_image_name)\n",
        "  foreground = foreground.astype(float)\n",
        "  background = background.astype(float)\n",
        "  alpha = alpha.astype(float)/255\n",
        "  foreground = cv2.multiply(alpha, foreground)\n",
        "  background = cv2.multiply(1.0 - alpha, background)\n",
        "  res = cv2.add(foreground, background)\n",
        "  cv2.imwrite('alpha_blending_' + \n",
        "              foreground_image_name + '_' + \n",
        "              background_image_name + '_' + \n",
        "              alpha_mask_image_name + '.jpg', res)\n",
        "\n",
        "\n",
        "alpha_blending('ph1.jpg','ph2.jpg','ph1.jpg')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdlsMBZXVo7I"
      },
      "source": [
        "# задание 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM2qNlPHVw8R"
      },
      "source": [
        "В пирамиде Гаусса последующие изображения уменьшаются с использованием среднего значения по Гауссу ( размытие по Гауссу ) и уменьшаются в масштабе. Каждый пиксель, содержащий локальное среднее значение, соответствует пикселю соседства на нижнем уровне пирамиды. Этот метод особенно используется при синтезе текстур.\n",
        "\n",
        "Пирамида Лапласа очень похожа на пирамиду Гаусса, но сохраняет различие размытых версий между каждым уровнем. Только наименьший уровень не является разностным изображением, чтобы можно было реконструировать изображение с высоким разрешением с использованием разностных изображений на более высоких уровнях. Этот метод можно использовать при сжатии изображений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ066rkgV2ji"
      },
      "source": [
        "def blending(image_name_1, image_name_2, height=6):\n",
        "    A = cv2.imread(image_name_1)\n",
        "    B = cv2.imread(image_name_2)\n",
        "\n",
        "    # пирамида Гаусса для A\n",
        "    G = A.copy()\n",
        "    gpA = [G]\n",
        "    for i in range(height):\n",
        "        G = cv2.pyrDown(G)\n",
        "        gpA.append(G)\n",
        "\n",
        "    # пирамида Гаусса для B\n",
        "    G = B.copy()\n",
        "    gpB = [G]\n",
        "    for i in range(height):\n",
        "        G = cv2.pyrDown(G)\n",
        "        gpB.append(G)\n",
        "\n",
        "    # пирамида Лапласа для A\n",
        "    lpA = [gpA[height - 1]]\n",
        "    for i in range(height - 1, 0, -1):\n",
        "        GE = cv2.pyrUp(gpA[i])\n",
        "        rows, cols, _ = gpA[i - 1].shape\n",
        "        GE = GE[:rows, :cols]\n",
        "        L = cv2.subtract(gpA[i - 1], GE)\n",
        "        lpA.append(L)\n",
        "\n",
        "    # пирамида Лапласа для B\n",
        "    lpB = [gpB[height - 1]]\n",
        "    for i in range(height - 1, 0, -1):\n",
        "        GE = cv2.pyrUp(gpB[i])\n",
        "        rows, cols, _ = gpB[i - 1].shape\n",
        "        GE = GE[:rows, :cols]\n",
        "        L = cv2.subtract(gpB[i - 1], GE)\n",
        "        lpB.append(L)\n",
        "\n",
        "    # соединяем левые и правые части на каждом уровне пирамид\n",
        "    LS = []\n",
        "    for la, lb in zip(lpA, lpB):\n",
        "        _, cols, _ = la.shape\n",
        "        ls = np.hstack((la[:, :int(cols / 2)], lb[:, int(cols / 2):]))\n",
        "        LS.append(ls)\n",
        "\n",
        "    ls_ = LS[0]\n",
        "    for i in range(1, height):\n",
        "        ls_ = cv2.pyrUp(ls_)\n",
        "        rows, cols, _ = LS[i].shape\n",
        "        ls_ = ls_[:rows, :cols]\n",
        "        ls_ = cv2.add(ls_, LS[i])\n",
        "\n",
        "    # объединение двух половин без блендинга\n",
        "    real = np.hstack((A[:, :int(cols / 2)], B[:, int(cols / 2):]))\n",
        "\n",
        "    cv2.imwrite('pyramid_blending_' + str(height) + '.jpg', ls_)\n",
        "    cv2.imwrite('direct_blending.jpg', real)\n",
        "\n",
        "\n",
        "blending(place_to_root('content/ph1.jpg'), place_to_root('content/ph2.jpg'), height = 16)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU8PCvOoWxpb"
      },
      "source": [
        "# задание 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0QWRLs7W2Nr"
      },
      "source": [
        "Каскады Хаара – наборы масок, прямоугольных окошек, каждое из которых представляет собой изображение с неким черно-белым узором (комбинацией черных и белых частей). Таких масок может быть неограниченное множество, сложность узоров может также разниться"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXyOYhNZW_6E",
        "outputId": "b7e3bee5-a7a8-45d5-b0eb-6a5b9e3b0f2d"
      },
      "source": [
        "!find / -depth -maxdepth 100 -type d -name 'cv2'\n",
        "haar_path = '/usr/local/lib/python3.7/dist-packages/cv2/data/'\n",
        "haar_cascade = 'haarcascade_frontalface_default.xml'"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/cv2\n",
            "/usr/local/lib/python2.7/dist-packages/cv2\n",
            "find: ‘/proc/191/task/191/net’: Invalid argument\n",
            "find: ‘/proc/191/net’: Invalid argument\n",
            "/tensorflow-1.15.2/python2.7/cv2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy9cGNsrY-jS"
      },
      "source": [
        "На вход подается путь к изображению и путь к xml-файлу с каскадом Хаара. Считываем изображение, переводим его в градации серого, и запускаем поиск лиц с помощью detectMultiScale — общая функция для распознавания как лиц, так и объектов. Чтобы функция искала именно лица, мы передаём ей соответствующий каскад.\n",
        "\n",
        "Функция detectMultiScale принимает 4 параметра:\n",
        "\n",
        "Обрабатываемое изображение в градации серого.\n",
        "\n",
        "scaleFactor компенсирует перспективу, потому что некоторые лица могут быть больше других, поскольку находятся ближе, чем остальные.\n",
        "\n",
        "minNeighbors определяет количество объектов вокруг лица. Чем больше значение этого параметра, тем больше аналогичных объектов необходимо алгоритму, чтобы он определил текущий объект, как лицо. Слишком маленькое значение увеличит количество ложных срабатываний, а слишком большое сделает алгоритм более требовательным.\n",
        "\n",
        "minSize определяет непосредственно размер областей. Затем обводим распознанные лица рамкой и сохраняем изображение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee1MtqtvZF9y"
      },
      "source": [
        "def haar_function(image_name, \n",
        "         cascade_path, \n",
        "         scale_factor=1.1, \n",
        "         min_neighbors=5, \n",
        "         min_size=(10, 10)):\n",
        "  cascade = cv2.CascadeClassifier(cascade_path)\n",
        "  image = cv2.imread(image_name)\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  detected = cascade.detectMultiScale(\n",
        "      gray,\n",
        "      scaleFactor=scale_factor,\n",
        "      minNeighbors=min_neighbors,\n",
        "      minSize=min_size)\n",
        "  print('На картинке обнаружено :', str(len(detected)))\n",
        "  for (x, y, w, h) in detected:\n",
        "      cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "  cv2.imwrite('haar_' + \n",
        "              str(scale_factor) + '_' + \n",
        "              str(min_neighbors) + '_' + \n",
        "              str(min_size) + '_' + image_name, image)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRhJN6_MgIHJ"
      },
      "source": [
        "file_id_for_1 = '1GKkO7UyBXFAoRm9DsgOyBBd5t0QYXv2O'\n",
        "file_name_for_1 = '1.jpg'\n",
        "download_data(file_id_for_1, file_name_for_1)\n",
        "file_id_for_2 = '17LyfpYRjLxdC_4GbX7lBrML5uuJsYhra'\n",
        "file_name_for_2 = '2.jpg'\n",
        "download_data(file_id_for_2, file_name_for_2)\n",
        "file_id_for_3 = '1ju-EmubGvw3aCe2CGq0D-mFzAhUSwHYT'\n",
        "file_name_for_3 = '3.jpg'\n",
        "download_data(file_id_for_3, file_name_for_3)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwfqC_1NZOVA",
        "outputId": "222e2301-7826-412b-f484-ef2311ff5ff4"
      },
      "source": [
        "haar_function('3.jpg', haar_path + haar_cascade)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "На картинке обнаружено : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka2oTOXzZUQP",
        "outputId": "30568a8c-a5c0-42a2-d859-20048baf6fa9"
      },
      "source": [
        "haar_function('1.jpg', haar_path + haar_cascade, scale_factor=1.2, min_size=(150, 150), min_neighbors=5)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "На картинке обнаружено : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAjQb_x-ZYnb",
        "outputId": "1606dcea-6d6f-451d-e526-0b93c12842f8"
      },
      "source": [
        "haar_function('2.jpg', haar_path + haar_cascade, scale_factor=1.3, min_neighbors=2)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "На картинке обнаружено : 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj0PzH6ehvar"
      },
      "source": [
        "# задание 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNaq7bzKh2IO"
      },
      "source": [
        "Метод Transfer Learning на примере распознавания изображений с мебелью.\n",
        "\n",
        "Если перед нами встает задача распознавания изображений, можно воспользоваться готовым сервисом. Однако, если нужно обучить модель на собственном наборе данных, то придется делать это самостоятельно.\n",
        "\n",
        "Для таких типовых задач, как классификация изображений, можно воспользоваться готовой архитектурой (AlexNet, VGG, Inception, ResNet и т.д.) и обучить нейросеть на своих данных. Реализации таких сетей с помощью различных фреймворков уже существуют, так что на данном этапе можно использовать одну из них как черный ящик, не вникая глубоко в принцип её работы.\n",
        "\n",
        "Однако, глубокие нейронные сети требовательны к большим объемам данных для сходимости обучения. И зачастую в нашей частной задаче недостаточно данных для того, чтобы хорошо натренировать все слои нейросети. Transfer Learning решает эту проблему."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaA0qXkvh299",
        "outputId": "d77415c4-250b-48ed-d7bd-4a1bf8600202"
      },
      "source": [
        "!pip install albumentations"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6wN3RqpxJyp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWkuBfRoiQoA",
        "outputId": "e3c11540-2557-47b6-fd23-0fafbfb7b3be"
      },
      "source": [
        "def download_data(file_id, file_name):\n",
        "  import io\n",
        "  from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "  request = drive_service.files().get_media(fileId=file_id)\n",
        "  downloaded = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(downloaded, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "    \n",
        "  downloaded.seek(0)\n",
        "  with open(file_name, 'wb') as f:\n",
        "    f.write(downloaded.read())\n",
        "  \n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "\n",
        "file_id = '1IyU2wPwKlrjVgKI4wejg849PssnUR4ZG'\n",
        "file_name = 'task6.zip'\n",
        "\n",
        "download_data(file_id, file_name)\n",
        "!unzip task6.zip"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  task6.zip\n",
            "   creating: pet/cat/\n",
            "  inflating: pet/cat/cat.0.jpg       \n",
            "  inflating: pet/cat/cat.1.jpg       \n",
            "  inflating: pet/cat/cat.10.jpg      \n",
            "  inflating: pet/cat/cat.11.jpg      \n",
            "  inflating: pet/cat/cat.12.jpg      \n",
            "  inflating: pet/cat/cat.13.jpg      \n",
            "  inflating: pet/cat/cat.14.jpg      \n",
            "  inflating: pet/cat/cat.15.jpg      \n",
            "  inflating: pet/cat/cat.16.jpg      \n",
            "  inflating: pet/cat/cat.17.jpg      \n",
            "  inflating: pet/cat/cat.18.jpg      \n",
            "  inflating: pet/cat/cat.19.jpg      \n",
            "  inflating: pet/cat/cat.2.jpg       \n",
            "  inflating: pet/cat/cat.20.jpg      \n",
            "  inflating: pet/cat/cat.21.jpg      \n",
            "  inflating: pet/cat/cat.22.jpg      \n",
            "  inflating: pet/cat/cat.23.jpg      \n",
            "  inflating: pet/cat/cat.24.jpg      \n",
            "  inflating: pet/cat/cat.25.jpg      \n",
            "  inflating: pet/cat/cat.26.jpg      \n",
            "  inflating: pet/cat/cat.27.jpg      \n",
            "  inflating: pet/cat/cat.28.jpg      \n",
            "  inflating: pet/cat/cat.29.jpg      \n",
            "  inflating: pet/cat/cat.3.jpg       \n",
            "  inflating: pet/cat/cat.30.jpg      \n",
            "  inflating: pet/cat/cat.31.jpg      \n",
            "  inflating: pet/cat/cat.32.jpg      \n",
            "  inflating: pet/cat/cat.33.jpg      \n",
            "  inflating: pet/cat/cat.34.jpg      \n",
            "  inflating: pet/cat/cat.35.jpg      \n",
            "  inflating: pet/cat/cat.36.jpg      \n",
            "  inflating: pet/cat/cat.37.jpg      \n",
            "  inflating: pet/cat/cat.38.jpg      \n",
            "  inflating: pet/cat/cat.39.jpg      \n",
            "  inflating: pet/cat/cat.4.jpg       \n",
            "  inflating: pet/cat/cat.40.jpg      \n",
            "  inflating: pet/cat/cat.41.jpg      \n",
            "  inflating: pet/cat/cat.42.jpg      \n",
            "  inflating: pet/cat/cat.43.jpg      \n",
            "  inflating: pet/cat/cat.44.jpg      \n",
            "  inflating: pet/cat/cat.45.jpg      \n",
            "  inflating: pet/cat/cat.46.jpg      \n",
            "  inflating: pet/cat/cat.47.jpg      \n",
            "  inflating: pet/cat/cat.48.jpg      \n",
            "  inflating: pet/cat/cat.49.jpg      \n",
            "  inflating: pet/cat/cat.5.jpg       \n",
            "  inflating: pet/cat/cat.50.jpg      \n",
            "  inflating: pet/cat/cat.51.jpg      \n",
            "  inflating: pet/cat/cat.52.jpg      \n",
            "  inflating: pet/cat/cat.53.jpg      \n",
            "  inflating: pet/cat/cat.54.jpg      \n",
            "  inflating: pet/cat/cat.55.jpg      \n",
            "  inflating: pet/cat/cat.6.jpg       \n",
            "  inflating: pet/cat/cat.7.jpg       \n",
            "  inflating: pet/cat/cat.8.jpg       \n",
            "  inflating: pet/cat/cat.9.jpg       \n",
            "   creating: pet/dog/\n",
            "  inflating: pet/dog/dog.12434.jpg   \n",
            "  inflating: pet/dog/dog.12435.jpg   \n",
            "  inflating: pet/dog/dog.12436.jpg   \n",
            "  inflating: pet/dog/dog.12437.jpg   \n",
            "  inflating: pet/dog/dog.12438.jpg   \n",
            "  inflating: pet/dog/dog.12439.jpg   \n",
            "  inflating: pet/dog/dog.12440.jpg   \n",
            "  inflating: pet/dog/dog.12441.jpg   \n",
            "  inflating: pet/dog/dog.12442.jpg   \n",
            "  inflating: pet/dog/dog.12443.jpg   \n",
            "  inflating: pet/dog/dog.12444.jpg   \n",
            "  inflating: pet/dog/dog.12445.jpg   \n",
            "  inflating: pet/dog/dog.12446.jpg   \n",
            "  inflating: pet/dog/dog.12447.jpg   \n",
            "  inflating: pet/dog/dog.12448.jpg   \n",
            "  inflating: pet/dog/dog.12449.jpg   \n",
            "  inflating: pet/dog/dog.12450.jpg   \n",
            "  inflating: pet/dog/dog.12451.jpg   \n",
            "  inflating: pet/dog/dog.12452.jpg   \n",
            "  inflating: pet/dog/dog.12453.jpg   \n",
            "  inflating: pet/dog/dog.12454.jpg   \n",
            "  inflating: pet/dog/dog.12455.jpg   \n",
            "  inflating: pet/dog/dog.12456.jpg   \n",
            "  inflating: pet/dog/dog.12457.jpg   \n",
            "  inflating: pet/dog/dog.12458.jpg   \n",
            "  inflating: pet/dog/dog.12459.jpg   \n",
            "  inflating: pet/dog/dog.12460.jpg   \n",
            "  inflating: pet/dog/dog.12461.jpg   \n",
            "  inflating: pet/dog/dog.12462.jpg   \n",
            "  inflating: pet/dog/dog.12463.jpg   \n",
            "  inflating: pet/dog/dog.12464.jpg   \n",
            "  inflating: pet/dog/dog.12465.jpg   \n",
            "  inflating: pet/dog/dog.12466.jpg   \n",
            "  inflating: pet/dog/dog.12467.jpg   \n",
            "  inflating: pet/dog/dog.12468.jpg   \n",
            "  inflating: pet/dog/dog.12469.jpg   \n",
            "  inflating: pet/dog/dog.12470.jpg   \n",
            "  inflating: pet/dog/dog.12471.jpg   \n",
            "  inflating: pet/dog/dog.12472.jpg   \n",
            "  inflating: pet/dog/dog.12473.jpg   \n",
            "  inflating: pet/dog/dog.12474.jpg   \n",
            "  inflating: pet/dog/dog.12475.jpg   \n",
            "  inflating: pet/dog/dog.12476.jpg   \n",
            "  inflating: pet/dog/dog.12477.jpg   \n",
            "  inflating: pet/dog/dog.12478.jpg   \n",
            "  inflating: pet/dog/dog.12479.jpg   \n",
            "  inflating: pet/dog/dog.12480.jpg   \n",
            "  inflating: pet/dog/dog.12481.jpg   \n",
            "  inflating: pet/dog/dog.12482.jpg   \n",
            "  inflating: pet/dog/dog.12483.jpg   \n",
            "  inflating: pet/dog/dog.12484.jpg   \n",
            "  inflating: pet/dog/dog.12485.jpg   \n",
            "  inflating: pet/dog/dog.12486.jpg   \n",
            "  inflating: pet/dog/dog.12487.jpg   \n",
            "  inflating: pet/dog/dog.12488.jpg   \n",
            "  inflating: pet/dog/dog.12489.jpg   \n",
            "   creating: pet/sl/\n",
            "  inflating: pet/sl/sl.1.jpg         \n",
            "  inflating: pet/sl/sl.10.jpg        \n",
            "  inflating: pet/sl/sl.11.jpg        \n",
            "  inflating: pet/sl/sl.12.jpg        \n",
            "  inflating: pet/sl/sl.13.jpg        \n",
            "  inflating: pet/sl/sl.14.jpg        \n",
            "  inflating: pet/sl/sl.15.jpg        \n",
            "  inflating: pet/sl/sl.16.jpg        \n",
            "  inflating: pet/sl/sl.17.jpg        \n",
            "  inflating: pet/sl/sl.18.jpg        \n",
            "  inflating: pet/sl/sl.19.jpg        \n",
            "  inflating: pet/sl/sl.2.jpg         \n",
            "  inflating: pet/sl/sl.20.jpg        \n",
            "  inflating: pet/sl/sl.3.jpg         \n",
            "  inflating: pet/sl/sl.4.jpg         \n",
            "  inflating: pet/sl/sl.5.jpg         \n",
            "  inflating: pet/sl/sl.6.jpg         \n",
            "  inflating: pet/sl/sl.7.jpg         \n",
            "  inflating: pet/sl/sl.8.jpg         \n",
            "  inflating: pet/sl/sl.9.jpg         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ariyfKKtvceD",
        "outputId": "4cbe8885-db95-4eee-9acd-1c69cc38e386"
      },
      "source": [
        "filenames = []\n",
        "labels = []\n",
        "path = 'pet'\n",
        "for idx, class_dir in enumerate(os.listdir('pet')):\n",
        "  print(f\"берем файлы из папки \\\"{class_dir}\\\" и даем им класс {idx}\")\n",
        "  \n",
        "  # не берем файлы кроме .jpg .jpeg и .png\n",
        "  for file in os.listdir(os.path.join('pet', class_dir)):\n",
        "    if not file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "      continue\n",
        "      \n",
        "    filenames.append(os.path.join('pet', class_dir, file))\n",
        "    labels.append(idx)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "берем файлы из папки \"cat\" и даем им класс 0\n",
            "берем файлы из папки \"dog\" и даем им класс 1\n",
            "берем файлы из папки \"sl\" и даем им класс 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyuywbFN3qkL"
      },
      "source": [
        "Разбиваем датасет на тренировочную и тестовую выборки в отношении 80/20. Функция add_pad служит для добавления полей к изображениям, чтобы привести их к квадратному формату.\n",
        "\n",
        "Функция resize меняет разрешение изображения.\n",
        "\n",
        "Функция transform_album применяет аугментации к изображению."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LST_UL9b3rgv"
      },
      "source": [
        "train_filenames, test_filenames, train_labels, test_labels = train_test_split(filenames, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "def add_pad(img, shape):\n",
        "    color_pick = img[0][0]\n",
        "    padded_img = color_pick * np.ones(shape + img.shape[2:3], dtype=np.uint8)\n",
        "    x_offset = int((padded_img.shape[0] - img.shape[0]) / 2)\n",
        "    y_offset = int((padded_img.shape[1] - img.shape[1]) / 2)\n",
        "    padded_img[x_offset:x_offset + img.shape[0], y_offset:y_offset + img.shape[1]] = img\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "def resize(img, shape):\n",
        "    scale = min(shape[0] * 1.0 / img.shape[0], shape[1] * 1.0 / img.shape[1])\n",
        "    if scale != 1:\n",
        "        img = cv2.resize(img, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
        "    return img\n",
        "\n",
        "\n",
        "def transform_album(image):\n",
        "  transform = A.Compose([\n",
        "        A.RandomRotate90(),\n",
        "        A.Flip(),\n",
        "        A.Transpose(),\n",
        "        A.OneOf([\n",
        "            A.IAAAdditiveGaussianNoise(),\n",
        "            A.GaussNoise(),\n",
        "        ], p=0.2),\n",
        "        A.OneOf([\n",
        "            A.MotionBlur(p=.2),\n",
        "            A.MedianBlur(blur_limit=3, p=0.1),\n",
        "            A.Blur(blur_limit=3, p=0.1),\n",
        "        ], p=0.2),\n",
        "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
        "        A.OneOf([\n",
        "            A.OpticalDistortion(p=0.3),\n",
        "            A.GridDistortion(p=.1),\n",
        "            A.IAAPiecewiseAffine(p=0.3),\n",
        "        ], p=0.2),\n",
        "        A.OneOf([\n",
        "            A.CLAHE(clip_limit=2),\n",
        "            A.IAASharpen(),\n",
        "            A.IAAEmboss(),\n",
        "            A.RandomBrightnessContrast(),            \n",
        "        ], p=0.3),\n",
        "        A.HueSaturationValue(p=0.3),\n",
        "    ])\n",
        "  random.seed(42)\n",
        "  augmented_image = transform(image=image)['image']\n",
        "  return augmented_image"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YtT5_tQ4N7W"
      },
      "source": [
        "Класс PetDataset возвращает по индексу преобразованное изображение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScOAH_NB4XcI"
      },
      "source": [
        "class PetDataset(Dataset):\n",
        "  def __init__(self, filenames, labels):\n",
        "    self._filenames = filenames\n",
        "    self._labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._filenames)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    filename = self._filenames[idx]\n",
        "    label = self._labels[idx]\n",
        "    img = cv2.imread(filename)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = resize(img, (224, 224))\n",
        "    img = add_pad(img, (224, 224))\n",
        "    img = transform_album(img)\n",
        "    img = torch.tensor(img, dtype=torch.float).permute(2, 0, 1) / 255.\n",
        "    return img, label"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rAhcLbB4gwl"
      },
      "source": [
        "В качестве исходной модели выступает претренированная ResNet50. Отсекаем последний слой на 1000 классов, заменяя его на слой с 3 классами. Создаются датасеты и даталоадеры для тренировочкой и тестовой выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "38539aa7e99740fe9644a03fc4064f31",
            "3d841cad1aa247beb66c4c5a30424683",
            "42b070f8a4584137873d45988792c391",
            "7575ca3ca6c14490942b9afaecd7c96a",
            "c09f1fc31ae04f8d8fe7e95a8c926658",
            "d6b3edcda3d741d796305e2457852088",
            "8804d894dc2d4880a78b607d1cb8412d",
            "f7f8b65391db4d05bf03e05ce06e0986"
          ]
        },
        "id": "OjtsyDhV4iZR",
        "outputId": "e77d308b-8b2a-46bf-d906-317bba9170bf"
      },
      "source": [
        "train_dataset = PetDataset(train_filenames, train_labels)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=64, num_workers=0)\n",
        "test_dataset = PetDataset(test_filenames, test_labels)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=108, num_workers=0)\n",
        "\n",
        "model = resnet50(pretrained=True)\n",
        "for param in model.parameters():\n",
        "  param.requires_grad=False\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 3)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38539aa7e99740fe9644a03fc4064f31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGNkz9-t4z2r"
      },
      "source": [
        "В качестве исходной модели выступает претренированная ResNet50. Отсекаем последний слой на 1000 классов, заменяя его на слой с 3 классами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdja_tLK5BYE"
      },
      "source": [
        "def run_test_on_epoch(model, epoch, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_accuracy = []\n",
        "      test_real = []\n",
        "      for batch_x, batch_y in tqdm(test_loader):\n",
        "          outputs = model(batch_x.to('cuda')).detach().cpu().numpy()\n",
        "          test_accuracy.append(outputs)\n",
        "          test_real.append(batch_y.detach().cpu().numpy())\n",
        "      print(\"Epoch\", epoch, \"test accuracy\", accuracy_score(np.hstack(test_real), np.argmax(np.hstack(test_accuracy), axis=1)))\n",
        "    model.train()"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzL2p83t5DdK"
      },
      "source": [
        "Размораживаем последние 3 слоя и обучаем модели в течение 25 эпох."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZB3IZKV5oso"
      },
      "source": [
        "params = list(model.parameters())\n",
        "    for epoch in tqdm(range(25)):\n",
        "      params[-epoch].requires_grad = True\n",
        "      for batch_x, batch_y in train_dataloder:\n",
        "        optimizer.zero_grad()\n",
        "        image, label = batch\n",
        "        image = image.to('cuda')\n",
        "        label = label.to('cuda')\n",
        "        label_pred = model(image)\n",
        "        loss = criterion(label_pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      run_test_on_epoch(model, epoch, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}